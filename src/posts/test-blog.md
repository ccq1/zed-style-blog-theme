---
slug: 'ai-70-problem-addy-osmani'
title: "AI's 70% Problem"
summary: "With Addy Osmani - AI can rapidly produce 70% of a solution, but that final 30% remains as challenging as ever."
date: 'Nov 24, 2025'
author: 'Addy Osmani'
authorAvatar: 'https://avatars.githubusercontent.com/u/78813459?v=4'
readTime: '8 min'
category: 'Thoughts'
tags: ['AI', 'Development', 'Productivity']
coverImage: 'https://images.unsplash.com/photo-1677442136019-21780ecad995?q=80&w=2070&auto=format&fit=crop'
---

AI's 70% Problem
Addy Osmani

From the Agentic Engineering Sessions

|
# Aired on November 6th, 2025

We hosted Addy Osmani, who works on AI and dev tools at Google's Chrome Developer Experience team, to talk about what he calls the "70% problem" in AI coding.

Over the past two years, Addy has been tracking AI adoption patterns at Google, where over 30% of code is now AI-generated, and across the industry at conferences like Lead Dev. He's studied trust metrics, productivity claims, and what actually happens when teams scale agentic engineering beyond prototypes.

His experiences reveal a pattern: AI can rapidly produce 70% of a solution, but that final 30% – edge cases, security, production integration – remains as challenging as ever. Meanwhile, trust in AI-generated code is declining even as adoption increases.

You can watch the full session on YouTube or read below for selected quotes from the session.

# AI Gets You 70% of the Way
"AI coding tools can get you most of the way to a solution, but not all the way. It's deceptively convincing. You can get a UI quickly, write a few prompts, even if you write a PRD you can get something that looks functional. But it can be held together with duct tape behind the scenes." — Addy Osmani

"AI can rapidly produce maybe 70% of the code for an app, for a feature. So the scaffolding, the obvious patterns. But the remaining 30%—things like edge cases where you might have to put in additional debugging, integration with production systems, making sure that your security, your API keys, all of that stuff is in a healthy place—that can be just as time consuming as it ever was." — Addy Osmani

"If you're using AI to generate the code, using AI to test the code, I think that at some point you're probably gonna try throwing AI into the code review loop as well. And at that point, AI is just doing the entire thing. You don't really know what's happening at all." — Addy Osmani

# The Trust Problem
"While adoption is in a really good place, trust is surprisingly low and it's declining. Favorable views about AI coding kind of dropped from 70 to 60% within two years, and about 30% of people are reporting little to no trust in AI generated code at all. Which is kind of wild given how much we're relying on this now." — Addy Osmani

"If you're not paying attention, you can end up—you don't wanna be on Hacker News for the wrong reasons, is a short version of this." — Addy Osmani

#The Two Steps Back Pattern
"You'll try to fix this bug. AI suggests a change that seems reasonable. Maybe it's given you a plan in your IDE. The fix is gonna break something else. You're gonna ask AI to fix that issue and it's gonna create two more problems. Rinse, repeat. Sometimes it's five new problems." — Addy Osmani

"If I ask AI to go and do a thing and it ends up rewriting code in five different places, I have no idea how anything works or how anything connects. A fundamental part of it for me is at least go back and understand how it all works." — Addy Osmani

# Understanding the Code is Key
"The really big difference is that you are keeping the human engineer firmly in control. You are responsible for thinking about architecture, reviewing the code, understanding every line. You have to make sure you're understanding what AI is generating for you, so you are on the hook for making sure the final product is secure, scalable, maintainable." — Addy Osmani

"AI is a tool. If your name is on there, when that code is getting submitted, you are responsible for what you submitted. So you need to make sure that you're reviewing it." — Addy Osmani

# Reality Check on Productivity
"Often on Twitter, when we see people citing these very high percentage numbers about their productivity gains, if you zoom in, often those are companies that are doing greenfield development on something completely fresh. They don't have technical debt, they don't have all of the baggage that usually comes with traditional software engineering on something that is real and has existed for a while." — Addy Osmani

"Developer productivity is 1X, 2X. Maybe they can complete 20% more tasks than they could before. But we're also starting to see side effects. We're actually starting to see that code review is becoming the new bottleneck." — Addy Osmani

# Advice for Junior Developers
"It is in fact really, really motivating to be able to do whatever is gonna help you build something quickly. Make sure you are going back and actually taking the time to understand what it is that was being generated." — Addy Osmani

"Be curious. Use AI as a learning aid while still improving your motivation, your feeling about yourself building stuff." — Addy Osmani

"Five years ago, we would still see lots of people at every level going to Stack Overflow and in some cases just blindly copying whatever's been most voted as the solution for a problem. Was it actually the right solution? We learn years later, like, oh wait, how did I ship this to production? There are better ways of doing it. So it's okay to be imperfect just as long as you continue to be curious and are open to learning." — Addy Osmani
